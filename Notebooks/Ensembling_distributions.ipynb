{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# System\n",
    "import os\n",
    "import sys\n",
    "import inspect\n",
    "import tabulate\n",
    "import time\n",
    "\n",
    "# Data processing\n",
    "import numpy as np\n",
    "import math as m\n",
    "\n",
    "# Results presentation\n",
    "from tqdm import tqdm as tqdm\n",
    "from IPython.display import clear_output\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# NN related stuff\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "current_dir = os.path.dirname(os.path.abspath(inspect.getfile(inspect.currentframe())))\n",
    "parent_dir = os.path.dirname(current_dir)\n",
    "sys.path.insert(0, parent_dir) \n",
    "\n",
    "import data\n",
    "import models\n",
    "import utils\n",
    "import correlation\n",
    "import regularization\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GlobalArguments():\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.model       = 'ConvFCSimple'\n",
    "        self.model2      = 'ConvFCSimpleTanh'\n",
    "        self.dataset     = 'CIFAR100'\n",
    "        self.data_path   = '../Data/'\n",
    "        self.batch_size  = 128\n",
    "        self.num_workers = 4\n",
    "        self.transform   = 'VGG'\n",
    "        self.use_test    = True\n",
    "        self.models_path = 'Checkpoints/'\n",
    "        self.n_models    = 40\n",
    "        self.ckpt        = '../Checkpoints/FGE/CIFAR100/ConvFCSimple/ind_grad_boost/classic/lr_auto/0.01-0.0001_100_auto_0/fge-200.pt'\n",
    "        self.boost_ckpts = '../Checkpoints/FGE/CIFAR100/ConvFCSimple/ind_grad_boost/classic/lr_auto/0.01-0.0001_100_auto_0/'\n",
    "        self.device      = 0\n",
    "args = GlobalArguments()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda:' + str(args.device) if torch.cuda.is_available() else 'cpu'\n",
    "torch.cuda.set_device(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConvFCSimpleBase(\n",
       "  (conv_part): Sequential(\n",
       "    (0): Conv2d(3, 8, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): MaxPool2d(kernel_size=3, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (6): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (7): ReLU(inplace=True)\n",
       "    (8): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (fc_part): Sequential(\n",
       "    (0): Linear(in_features=392, out_features=100, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Linear(in_features=100, out_features=100, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if   args.dataset == \"CIFAR10\":\n",
    "    num_classes = 10\n",
    "elif args.dataset == \"CIFAR100\":\n",
    "    num_classes = 100\n",
    "    \n",
    "architecture = getattr(models, args.model)\n",
    "architecture2 = getattr(models, args.model2)\n",
    "model = architecture.base(num_classes=num_classes, **architecture.kwargs)\n",
    "checkpoint = torch.load(args.ckpt)\n",
    "model.load_state_dict(checkpoint['model_state'])\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Initial logits :\n",
      "Shape : torch.Size([50000, 100]) Logits_mean : 0.03131427243351936\n",
      "Max : 27.466276168823242 Min : -27.578441619873047\n",
      "You are going to run models on the test set. Are you sure?\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "loaders, num_classes = data.loaders_gb(\n",
    "    args.dataset,\n",
    "    args.data_path,\n",
    "    args.batch_size,\n",
    "    args.num_workers,\n",
    "    args.transform,\n",
    "    args.use_test,\n",
    "    shuffle_train=False,\n",
    "    logits_generator=regularization.dataset_logits_generator(\n",
    "        model,\n",
    "        transform=getattr(getattr(data.Transforms, args.dataset), args.transform).train,\n",
    "        batch_size=args.batch_size),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:00<00:00, 190.01it/s]\n"
     ]
    }
   ],
   "source": [
    "models_list_fge = []\n",
    "models_weights  = []\n",
    "# indicies = range (690, 1011, 20)\n",
    "indicies = [i for i in range (299, 1000, 100)]\n",
    "indicies.insert(0, 200)\n",
    "\n",
    "for i in tqdm(indicies):\n",
    "    model = architecture.base(num_classes=num_classes, **architecture.kwargs)\n",
    "    checkpoint = torch.load(args.boost_ckpts + 'fge-' + str(i) + '.pt', map_location=torch.device('cpu'))\n",
    "    model.load_state_dict(checkpoint['model_state'])\n",
    "    models_list_fge.append(model)\n",
    "    models_weights .append(checkpoint['boost_weight'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# models_list_fge = []\n",
    "# models_weights  = []\n",
    "# # indicies = range (690, 1011, 20)\n",
    "# indicies = [i for i in range (399, 1600, 200)]\n",
    "# indicies.insert(0, 200)\n",
    "\n",
    "# for i in tqdm(indicies):\n",
    "#     if i == 200:\n",
    "#         model = architecture.base(num_classes=num_classes, **architecture.kwargs)\n",
    "#     else:\n",
    "#         model = architecture.base(num_classes=num_classes, **architecture2.kwargs)\n",
    "#     checkpoint = torch.load(args.boost_ckpts + 'fge-' + str(i) + '.pt', map_location=torch.device('cpu'))\n",
    "#     model.load_state_dict(checkpoint['model_state'])\n",
    "#     models_list_fge.append(model)\n",
    "#     models_weights .append(checkpoint['boost_weight'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def outputs_target_labels(model, dataloader, device=torch.device('cpu')):\n",
    "    with torch.no_grad():\n",
    "        model.to(device)\n",
    "        target_list = []\n",
    "        output_list = []\n",
    "        labels_list = []\n",
    "        for input, labels, logits in dataloader:\n",
    "            input  = input .to(device)\n",
    "            logits = logits.to(device).detach()\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            target = utils.one_hot(labels, logits.shape[1]) - F.softmax(logits, dim=1)\n",
    "            output = model(input)\n",
    "\n",
    "            output_list.append(output.cpu())\n",
    "            target_list.append(target.cpu())\n",
    "            labels_list.append(labels.cpu())\n",
    "\n",
    "        output_list = torch.cat(output_list, dim=0)\n",
    "        target_list = torch.cat(target_list, dim=0)\n",
    "        labels_list = torch.cat(labels_list, dim=0)\n",
    "    return output_list, target_list, labels_list\n",
    "\n",
    "def STD(tensor):\n",
    "    return ((tensor - tensor.mean(dim=0, keepdim=True))**2).mean().sqrt().item()\n",
    "\n",
    "def target_and_predicted_distributions(model_list, loaders, device=torch.device('cpu')):\n",
    "    table = {\n",
    "        'Iter'      : [],\n",
    "        'Weight'    : [],\n",
    "        'Trg_mean'  : [],\n",
    "        'Prd_mean'  : [],\n",
    "        'Trg_std'   : [],\n",
    "        'Prd_std'   : [],\n",
    "        'Mean_L1'   : [],\n",
    "        'Mean_L2'   : [],\n",
    "        'Train_acc' : [],\n",
    "        'Test_acc'  : [],\n",
    "        'Add_std_tr': [],\n",
    "        'Add_std_te': [],\n",
    "    }\n",
    "    criterion_L2 = torch.nn.MSELoss(reduction='none')\n",
    "    criterion_L1 = torch.nn.L1Loss(reduction='none')\n",
    "    \n",
    "    output_sum_train = 0.\n",
    "    output_sum_test  = 0.\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for iter in tqdm(range(len(model_list))):\n",
    "            model = model_list[0].eval().to(device)\n",
    "            \n",
    "            output_train, target_train, labels_train = outputs_target_labels(\n",
    "                model,\n",
    "                loaders['train'],\n",
    "                device=device)\n",
    "                \n",
    "            output_test, target_test, labels_test = outputs_target_labels(\n",
    "                model,\n",
    "                loaders['test'],\n",
    "                device=device)\n",
    "            \n",
    "            output_sum_train += models_weights[iter] * output_train\n",
    "            output_sum_test  += models_weights[iter] * output_test\n",
    "         \n",
    "            table['Iter'      ].append(iter)\n",
    "            table['Weight'    ].append(models_weights[iter])\n",
    "            table['Trg_mean'  ].append(target_test.mean().item())\n",
    "            table['Prd_mean'  ].append(output_test.mean().item())\n",
    "            table['Trg_std'   ].append(STD(target_test))\n",
    "            table['Prd_std'   ].append(STD(output_test))\n",
    "            table['Mean_L1'   ].append(criterion_L1(output_test, target_test).mean().item())\n",
    "            table['Mean_L2'   ].append(criterion_L2(output_test, target_test ).mean().item())\n",
    "            table['Train_acc' ].append(torch.eq(output_sum_train.argmax(dim=1), labels_train).float().mean().item())\n",
    "            table['Test_acc'  ].append(torch.eq(output_sum_test .argmax(dim=1), labels_test ).float().mean().item())\n",
    "            table['Add_std_tr'].append(STD(models_weights[iter] * output_train))\n",
    "            table['Add_std_te'].append(STD(models_weights[iter] * output_test))\n",
    "  \n",
    "            loaders['train'].dataset.update_logits(\n",
    "                models_weights[iter],\n",
    "                logits_generator=regularization.dataset_logits_generator(\n",
    "                    model,\n",
    "                    transform=getattr(getattr(\n",
    "                            data.Transforms,\n",
    "                            args.dataset),\n",
    "                        args.transform).train,\n",
    "                    batch_size = args.batch_size))\n",
    "        \n",
    "            loaders['test'].dataset.update_logits(\n",
    "                models_weights[iter],\n",
    "                logits_generator=regularization.dataset_logits_generator(\n",
    "                    model,\n",
    "                    transform=getattr(getattr(\n",
    "                            data.Transforms,\n",
    "                            args.dataset),\n",
    "                        args.transform).test,\n",
    "                    batch_size = args.batch_size))\n",
    "            \n",
    "            del model\n",
    "            del model_list[0]\n",
    "    return table\n",
    "            \n",
    "            \n",
    "#         regularization.logits_info(dataloader.dataset.logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = target_and_predicted_distributions(models_list_fge, loaders, device=torch.device('cuda'))\n",
    "print (tabulate.tabulate(table, headers='keys', tablefmt=\"grid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_grapfics(table, filename=None):\n",
    "    fig, ((ax1, ax2), (ax3, ax4), (ax5, ax6)) = plt.subplots(\n",
    "    nrows=3, ncols=2,\n",
    "    figsize=(10, 15))\n",
    "    \n",
    "    ax1.plot(table['Iter'], np.array(table['Train_acc']) * 100, marker='o')\n",
    "    ax1.set_title('Train accuracy')\n",
    "    ax1.set_xlabel('Iter')\n",
    "    ax1.set_ylabel('Train accuracy')\n",
    "    \n",
    "    ax2.plot(table['Iter'], np.array(table['Test_acc']) * 100, marker='o')\n",
    "    ax2.set_title('Test accuracy')\n",
    "    ax2.set_xlabel('Iter')\n",
    "    ax2.set_ylabel('Test accuracy')\n",
    "    \n",
    "    ax3.plot(table['Iter'][1:], table['Mean_L1'][1:], marker='o')\n",
    "    ax3.set_title('Mean L1 on test')\n",
    "    ax3.set_xlabel('Iter')\n",
    "    ax3.set_ylabel('L1')\n",
    "    \n",
    "    ax4.plot(table['Iter'][1:], table['Mean_L2'][1:], marker='o')\n",
    "    ax4.set_title('Mean L2 on test')\n",
    "    ax4.set_xlabel('Iter')\n",
    "    ax4.set_ylabel('L2')\n",
    "    \n",
    "    ax5.plot(table['Iter'][1:], table['Weight'][1:], marker='o')\n",
    "    ax5.set_title('Weight in boosting')\n",
    "    ax5.set_xlabel('Iter')\n",
    "    ax5.set_ylabel('Weight')\n",
    "    \n",
    "    ax6.plot(table['Iter'][1:], table['Add_std_tr'][1:], marker='o')\n",
    "    ax6.set_title('Added STD')\n",
    "    ax6.set_xlabel('Iter')\n",
    "    ax6.set_ylabel('STD')\n",
    "    \n",
    "    if filename is not None:\n",
    "        plt.savefig(filename + '.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print ('Lr : 0.01 - 0.0001')\n",
    "draw_grapfics(table, filename='figures/ConvFC_indGB_0.01-0.0001_200')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
